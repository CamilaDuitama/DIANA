2025-12-23 17:15:22,105 - __main__ - INFO - ==================================================
2025-12-23 17:15:22,105 - __main__ - INFO - Training final model with best hyperparameters
2025-12-23 17:15:22,105 - __main__ - INFO - ==================================================
2025-12-23 17:15:22,105 - __main__ - INFO - Model params: {
  "hidden_dims": [
    307,
    474,
    272
  ],
  "dropout": 0.1916894511329029,
  "activation": "relu",
  "use_batch_norm": false
}
2025-12-23 17:15:22,105 - __main__ - INFO - Trainer params: {
  "learning_rate": 0.001723369322527049,
  "weight_decay": 3.75062679509968e-05,
  "task_weights": {
    "sample_type": 0.9307526054899867,
    "community_type": 1.6222031999590159,
    "sample_host": 1.1909289698749999,
    "material": 1.810458861595924
  }
}
2025-12-23 17:15:22,105 - __main__ - INFO - Batch size: 96
2025-12-23 17:15:22,105 - __main__ - INFO - Loading training data from data/matrices/large_matrix_3070_with_frac/unitigs.frac.mat
2025-12-23 17:15:22,105 - diana.data.loader - INFO - Loading matrix from data/matrices/large_matrix_3070_with_frac/unitigs.frac.mat
2025-12-23 17:16:51,700 - diana.data.loader - INFO - Loaded 107480 features × 3070 samples (before transpose)
2025-12-23 17:16:51,701 - diana.data.loader - INFO - Transposed to 3070 samples × 107480 features
2025-12-23 17:16:51,701 - diana.data.loader - INFO - Reading sample IDs from data/matrices/large_matrix_3070_with_frac/kmer_matrix/kmtricks.fof
2025-12-23 17:16:51,704 - diana.data.loader - INFO - Sample IDs: ['ERR10114844', 'ERR10114845', 'ERR10114846']...
2025-12-23 17:16:51,960 - diana.data.loader - INFO - Loading metadata from data/metadata/DIANA_metadata.tsv
2025-12-23 17:16:51,970 - diana.data.loader - INFO - Metadata: 3070 rows × 48 columns
2025-12-23 17:16:52,015 - diana.data.loader - INFO - Metadata aligned to matrix sample order
2025-12-23 17:16:52,029 - __main__ - INFO - Full training data shape: (3070, 107480)
2025-12-23 17:16:52,030 - __main__ - INFO - Total samples: 3070
2025-12-23 17:16:52,031 - __main__ - INFO - Task 'sample_type': 2 classes
2025-12-23 17:16:52,032 - __main__ - INFO - Task 'community_type': 6 classes
2025-12-23 17:16:52,033 - __main__ - INFO - Task 'sample_host': 12 classes
2025-12-23 17:16:52,034 - __main__ - INFO - Task 'material': 13 classes
2025-12-23 17:16:52,034 - __main__ - INFO - Creating validation split: 10% for validation
2025-12-23 17:16:52,275 - __main__ - INFO - Sub-train samples: 2763
2025-12-23 17:16:52,276 - __main__ - INFO - Validation samples: 307
2025-12-23 17:16:52,276 - __main__ - INFO - Using device: cuda
2025-12-23 17:16:54,591 - __main__ - INFO - Starting training with validation-based early stopping...
/pasteur/appa/scratch/cduitama/EDID/decOM-classify/src/diana/training/trainer.py:191: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(best_model_path)
2025-12-23 17:17:36,790 - __main__ - INFO - Final model saved to: results/full_training/best_model.pth
2025-12-23 17:17:36,792 - __main__ - INFO - Training history saved to: results/full_training/training_history.json
2025-12-23 17:17:36,793 - __main__ - INFO - Label encoders saved to: results/full_training/label_encoders.json
2025-12-23 17:17:36,793 - __main__ - INFO - ==================================================
2025-12-23 17:17:36,794 - __main__ - INFO - Final training complete!
2025-12-23 17:17:36,794 - __main__ - INFO - ==================================================
