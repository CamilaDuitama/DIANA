2025-12-24 22:32:28 - root - INFO - Logging to file: results/training/diana_train.log
2025-12-24 22:32:28 - diana.cli.train - INFO - Using CPU
2025-12-24 22:32:28 - diana.cli.train - INFO - Starting hyperparameter optimization...
2025-12-24 22:32:28 - diana.cli.train - INFO -   Folds: 5, Trials: 50, Max Epochs: 200
2025-12-24 22:32:28 - diana.cli.train - INFO - Submitting SLURM array job...
2025-12-24 22:32:28 - diana.cli.train - INFO - Saved SLURM run config to results/training/cv_results/slurm_run_config.json
2025-12-24 22:32:28 - diana.cli.train - INFO - Submitted SLURM job: 61294720
2025-12-24 22:32:28 - diana.cli.train - INFO - Monitor with: squeue -j 61294720
2025-12-24 22:32:28 - diana.cli.train - INFO - Check logs in: results/logs
2025-12-24 22:32:28 - diana.cli.train - INFO - 
2025-12-24 22:32:28 - diana.cli.train - INFO - After job completion, run:
2025-12-24 22:32:28 - diana.cli.train - INFO -   diana-train multitask --output results/training --mode train
2025-12-24 22:32:28 - diana.cli.train - INFO - 
2025-12-24 22:32:28 - diana.cli.train - INFO - To check job status: sacct -j 61294720 --format=JobID,State,ExitCode,Elapsed
2025-12-24 22:32:28 - diana.cli.train - INFO - ==================================================
2025-12-24 22:32:28 - diana.cli.train - INFO - SLURM job submitted successfully
2025-12-24 22:32:28 - diana.cli.train - INFO - ==================================================
2025-12-24 22:32:28 - diana.cli.train - INFO - The pipeline will exit now. Jobs are running on SLURM.
2025-12-24 22:32:28 - diana.cli.train - INFO - After jobs complete, continue with:
2025-12-24 22:32:28 - diana.cli.train - INFO -   diana-train multitask --config configs/train_config.yaml --output results/training --mode aggregate
2025-12-24 22:32:28 - diana.cli.train - INFO - Then train the final model with:
2025-12-24 22:32:28 - diana.cli.train - INFO -   diana-train multitask --config configs/train_config.yaml --output results/training --mode train
2025-12-24 22:42:25 - root - INFO - Logging to file: results/training/diana_train.log
2025-12-24 22:42:25 - diana.cli.train - INFO - Using CPU
2025-12-24 22:42:25 - diana.cli.train - INFO - Aggregating fold results from cv_results/ directory...
2025-12-24 22:42:25 - diana.cli.train - INFO - Found 10 fold result directories
2025-12-24 22:42:25 - diana.cli.train - INFO - Aggregating cross-validation results...
2025-12-24 22:42:25 - diana.cli.train - INFO - Saved aggregated results to results/training/cv_results/aggregated_results.json
2025-12-24 22:42:25 - diana.cli.train - INFO - Saved best hyperparameters to results/training/cv_results/best_hyperparameters.json
2025-12-24 22:42:25 - diana.cli.train - INFO - Aggregation complete!
2025-12-24 22:42:25 - diana.cli.train - INFO - Best hyperparameters saved to: results/training/cv_results/best_hyperparameters.json
2025-12-24 22:42:25 - diana.cli.train - INFO - Aggregated metrics saved to: results/training/cv_results/aggregated_results.json
2025-12-24 22:42:25 - diana.cli.train - INFO - Aggregation complete! Continue with:
2025-12-24 22:42:25 - diana.cli.train - INFO -   diana-train multitask --config configs/train_config.yaml --output results/training --mode train
2025-12-24 22:43:19 - root - INFO - Logging to file: results/training/diana_train.log
2025-12-24 22:43:19 - diana.cli.train - INFO - Using CPU
2025-12-24 22:43:19 - diana.cli.train - INFO - ==================================================
2025-12-24 22:43:19 - diana.cli.train - INFO - Training final model with validation-based early stopping
2025-12-24 22:43:19 - diana.cli.train - INFO - ==================================================
2025-12-24 22:43:19 - diana.cli.train - INFO - Loading best hyperparameters from results/training/cv_results/best_hyperparameters.json
2025-12-24 22:43:19 - diana.cli.train - INFO - Hyperparameters: {
  "n_layers": 2.6,
  "hidden_dim_0": 307.2,
  "hidden_dim_1": 358.4,
  "hidden_dim_2": 224.0,
  "hidden_dim_3": 512.0,
  "dropout": 0.24008941768262765,
  "learning_rate": 0.0018070735350860004,
  "weight_decay": 0.00013646152308693173,
  "batch_size": 89.6,
  "use_batch_norm": 0.0,
  "activation": "relu",
  "task_weight_sample_type": 1.2191664079885853,
  "task_weight_community": 1.5572400633917634,
  "task_weight_host": 1.336836008310497,
  "task_weight_material": 1.581606959759543
}
2025-12-24 22:43:19 - diana.cli.train - INFO - Submitting SLURM job for final training...
2025-12-24 22:43:19 - diana.cli.train - INFO - Saved training config to results/training/final_training_config.json
2025-12-24 22:43:20 - diana.cli.train - INFO - Submitted SLURM job: 61296060
2025-12-24 22:43:20 - diana.cli.train - INFO - Monitor with: squeue -j 61296060
2025-12-24 22:43:20 - diana.cli.train - INFO - Check logs in: results/logs
2025-12-24 22:43:20 - diana.cli.train - INFO - Model will be saved to: results/training/best_model.pth
2025-12-24 22:43:20 - diana.cli.train - INFO - Pipeline complete!
2025-12-24 22:45:53 - root - INFO - Logging to file: results/training/diana_train.log
2025-12-24 22:45:53 - diana.cli.train - INFO - Using CPU
2025-12-24 22:45:53 - diana.cli.train - INFO - ==================================================
2025-12-24 22:45:53 - diana.cli.train - INFO - Training final model with validation-based early stopping
2025-12-24 22:45:53 - diana.cli.train - INFO - ==================================================
2025-12-24 22:45:53 - diana.cli.train - INFO - Loading best hyperparameters from results/training/cv_results/best_hyperparameters.json
2025-12-24 22:45:53 - diana.cli.train - INFO - Hyperparameters: {
  "n_layers": 2.6,
  "hidden_dim_0": 307.2,
  "hidden_dim_1": 358.4,
  "hidden_dim_2": 224.0,
  "hidden_dim_3": 512.0,
  "dropout": 0.24008941768262765,
  "learning_rate": 0.0018070735350860004,
  "weight_decay": 0.00013646152308693173,
  "batch_size": 89.6,
  "use_batch_norm": 0.0,
  "activation": "relu",
  "task_weight_sample_type": 1.2191664079885853,
  "task_weight_community": 1.5572400633917634,
  "task_weight_host": 1.336836008310497,
  "task_weight_material": 1.581606959759543
}
2025-12-24 22:45:53 - diana.cli.train - INFO - Submitting SLURM job for final training...
2025-12-24 22:45:53 - diana.cli.train - INFO - Saved training config to results/training/final_training_config.json
2025-12-24 22:45:53 - diana.cli.train - INFO - Submitted SLURM job: 61296891
2025-12-24 22:45:53 - diana.cli.train - INFO - Monitor with: squeue -j 61296891
2025-12-24 22:45:53 - diana.cli.train - INFO - Check logs in: results/logs
2025-12-24 22:45:53 - diana.cli.train - INFO - Model will be saved to: results/training/best_model.pth
2025-12-24 22:45:53 - diana.cli.train - INFO - Pipeline complete!
2025-12-24 22:50:06 - root - INFO - Logging to file: results/training/diana_train.log
2025-12-24 22:50:06 - diana.cli.train - INFO - Using CPU
2025-12-24 22:50:06 - diana.cli.train - INFO - ==================================================
2025-12-24 22:50:06 - diana.cli.train - INFO - Training final model with validation-based early stopping
2025-12-24 22:50:06 - diana.cli.train - INFO - ==================================================
2025-12-24 22:50:06 - diana.cli.train - INFO - Loading best hyperparameters from results/training/cv_results/best_hyperparameters.json
2025-12-24 22:50:06 - diana.cli.train - INFO - Hyperparameters: {
  "n_layers": 2.6,
  "hidden_dim_0": 307.2,
  "hidden_dim_1": 358.4,
  "hidden_dim_2": 224.0,
  "hidden_dim_3": 512.0,
  "dropout": 0.24008941768262765,
  "learning_rate": 0.0018070735350860004,
  "weight_decay": 0.00013646152308693173,
  "batch_size": 89.6,
  "use_batch_norm": 0.0,
  "activation": "relu",
  "task_weight_sample_type": 1.2191664079885853,
  "task_weight_community": 1.5572400633917634,
  "task_weight_host": 1.336836008310497,
  "task_weight_material": 1.581606959759543
}
2025-12-24 22:50:06 - diana.cli.train - INFO - Submitting SLURM job for final training...
2025-12-24 22:50:06 - diana.cli.train - INFO - Converted hyperparameters to nested structure:
2025-12-24 22:50:06 - diana.cli.train - INFO -   Model params: {'hidden_dims': [307, 358, 224], 'dropout': 0.24008941768262765, 'activation': 'relu', 'use_batch_norm': False}
2025-12-24 22:50:06 - diana.cli.train - INFO -   Trainer params: {'learning_rate': 0.0018070735350860004, 'weight_decay': 0.00013646152308693173, 'task_weights': {'sample_type': 1.2191664079885853, 'community_type': 1.5572400633917634, 'sample_host': 1.336836008310497, 'material': 1.581606959759543}}
2025-12-24 22:50:06 - diana.cli.train - INFO -   Batch size: 90
2025-12-24 22:50:06 - diana.cli.train - INFO - Saved training config to results/training/final_training_config.json
2025-12-24 22:50:07 - diana.cli.train - INFO - Submitted SLURM job: 61298442
2025-12-24 22:50:07 - diana.cli.train - INFO - Monitor with: squeue -j 61298442
2025-12-24 22:50:07 - diana.cli.train - INFO - Check logs in: results/logs
2025-12-24 22:50:07 - diana.cli.train - INFO - Model will be saved to: results/training/best_model.pth
2025-12-24 22:50:07 - diana.cli.train - INFO - Pipeline complete!
