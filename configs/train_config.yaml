# DIANA Training Configuration (CORRECTED FOR TRAIN SET ONLY)
# =============================================================
# This config ensures NO data leakage by using train_metadata.tsv
# which contains ONLY the 2609 training samples (not the 461 test samples)

data:
  features_path: data/matrices/large_matrix_3070_with_frac/unitigs.frac.mat
  metadata_path: data/splits/train_metadata.tsv  # ‚Üê CRITICAL: Train set only!

model:
  # Task definitions
  task_names:
    - sample_type
    - community_type
    - sample_host
    - material

training:
  # Hyperparameter optimization settings
  n_folds: 5              # Outer CV folds
  n_trials: 50            # Optuna trials per fold
  max_epochs: 200
  n_inner_splits: 3       # Inner CV for validation
  
  # Final model training
  validation_split: 0.1   # 10% of train set for early stopping
  early_stopping_patience: 20
  
  # Execution settings
  use_gpu: true
  use_slurm: true         # Submits SLURM array jobs for parallel fold training

# Optional: Specify best hyperparameters from previous optimization
# (diana-train will use these if mode=train, otherwise will optimize)
hyperparameters:
  model_params:
    hidden_dims: [307, 474, 272]
    dropout: 0.1916894511329029
    activation: relu
    use_batch_norm: false
  
  trainer_params:
    learning_rate: 0.001723369322527049
    weight_decay: 3.75062679509968e-05
    task_weights:
      sample_type: 0.9307526054899867
      community_type: 1.6222031999590159
      sample_host: 1.1909289698749999
      material: 1.810458861595924
  
  batch_size: 96
